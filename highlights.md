---
layout: default
is_grid: true
---

<div class="container">

<h1> Research Highlights </h1>

<br>
<h3> Theory of Neural Manifolds</h3>
<div class="cards">
<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/pub_imgs/chou2025geometry.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Geometry linked to untangling efficiency reveals structure and computation in neural populations </div>
    <div class="card-subtitle"> <!----Title---> Chi-Ning Chou, Royoung Kim, Luke A Arend, Yao-Yuan Yang, Brett D Mensh, Won Mok Shim, Matthew G Perich, SueYeon Chung </div> 
    <div class="card-body"> <!----Description---> We introduce GLUE (Geometry Linked to Untangling Efficiency) a data-driven analysis framework with manifold capacity theory, that links changes in the geometrical properties of neural activity patterns to representational untangling at the computational level. We applied GLUE to over seven neuroscience datasets—spanning multiple organisms, tasks, and recording techniques—and found that task-relevant representations untangle in many domains, including along the cortical hierarchy, through learning, and over the course of intrinsic neural dynamics. [<a id="external-link" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11996410/">pdf</a>] [<a id="external-link" href="assets/bib/chou2025geometry.html">bib</a>] <i> bioRxiv, 2025 </i> </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/wakhloo.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Linear Classification of Neural Manifolds with Correlated Variability </div>
    <div class="card-subtitle"> <!----Title---> Albert J. Wakhloo, Tamara J. Sussman, and SueYeon Chung </div> 
    <div class="card-body"> <!----Description--->  In this letter, we calculate how correlations between object representations affect the capacity, a measure of linear separability. We show that for spherical object manifolds, introducing correlations between centroids effectively pushes the spheres closer together, while introducing correlations between the spheres’ axes effectively shrinks their radii, revealing a duality between neural correlations and geometry [<a id="external-link" href="https://arxiv.org/pdf/2211.14961.pdf">pdf</a>][<a id="external-link" href="assets/bib/wakhloo.html">bib</a>] <i> Physical Review Letters, 2023 </i> </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/chung-and-abbott.png" height="300px" width="200px"/>
    <div class="card-title"> Neural population geometry: An approach for understanding biological and artificial neural networks</div> 
    <div class="card-subtitle"> SueYeon Chung, Larry Abbott </div> 
    <div class="card-body"> We highlight recent studies of neural population geometry: untangling in perception, classification theory of manifolds, abstraction in cognitive systems, topology underlying cognitive maps, dynamic untangling in motor systems, and a dynamic approach to cognition.   [<a id="external-link" href="https://reader.elsevier.com/reader/sd/pii/S0959438821001227?token=A35A4C64517A0C79DEC5D1818739BAABEB465C461F9E49F7DED819CB2B8B6A37596F353C4C04FA8C561E9CD86D2C1B2D&originRegion=us-east-1&originCreation=20230118192945">pdf</a>] [<a id="external-link" href="assets/bib/chung-and-abbott.html">bib</a>] <i> Current Opinion in Neurobiology, 2021</i> </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/chung2018.png" height="300px" width="200px"/>
    <div class="card-title"> <!----Title---> Classification and Geometry of General Perceptual Manifolds </div> 
    <div class="card-subtitle"> <!----Title---> Sueyeon Chung, Daniel D. Lee, Haim Sompolinsky  </div> 
    <div class="card-body"> <!----Description---> We develop a statistical mechanical theory for the linear classification of manifolds with arbitrary geometry, revealing a remarkable relation to the mathematics of conic decomposition. We show how special anchor points on the manifolds can be used to define novel geometrical measures of radius and dimension, which can explain the classification capacity for manifolds of various geometries. [<a id="external-link" href="https://journals.aps.org/prx/pdf/10.1103/PhysRevX.8.031003">pdf</a>] [<a id="external-link" href="assets/bib/chung2018.html">bib</a>] <i> Physical Review X, 2018 </i> </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/chung2016.png" height="300px" width="200px"/>
    <div class="card-title"> <!----Title---> Linear readout of object manifolds </div> 
    <div class="card-subtitle"> <!----Title---> Sueyeon Chung, Daniel D. Lee, Haim Sompolinsky </div> 
    <div class="card-body"> <!----Description---> We present a theory that characterizes the ability of a linear readout network, the perceptron, to classify objects from variable neural responses. We show how the readout perceptron capacity depends on the dimensionality, size, and shape of the object manifolds in its input neural representation. [<a id="external-link" href="https://drive.google.com/file/d/1rtsSztFNUG5NcDcotVp5cJGfqIO59gqY/view">pdf</a>] [<a id="external-link" href="assets/bib/chung2016.html">bib</a>] <i> Physical Review E, 2016 </i> </div>
</div>
</div>

<br>
<hr>
<h3> Manifold analysis as a population coding framework, and tools for neural data analysis and interpretable AI </h3>
<div class="cards">

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/pub_imgs/saraf2025variations.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Variations in neuronal selectivity create efficient representational geometries for perception </div> 
    <div class="card-subtitle"> <!----Title---> Sonica Saraf, J. Anthony Movshon, SueYeon Chung </div> 
    <div class="card-body"> <!----Description---> Neurons exhibit a wide variety of selective response properties, but the reasons for this diversity are unknown. Here, we related the distribution of neuronal tuning properties to the information capacity of the population. Our results from theory, simulations, and analysis of recordings from macaque primary visual cortex (V1) reveal that diversity of amplitude and bandwidth drive complementary changes to the representational geometry of a population. Amplitude diversity pushes the centers of the representations further apart, whereas bandwidth heterogeneity decorrelates the center locations. These geometric changes separate out representations for distinct stimuli, creating more efficient encoding. [<a id="external-link" href="https://www.biorxiv.org/content/10.1101/2025.06.26.661754v1">pdf</a>] [<a id="external-link" href="assets/bib/saraf2025variations.html">bib</a>] <i> bioRxiv, 2025 </i> </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/pub_imgs/chou2025geometry.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Geometry linked to untangling efficiency reveals structure and computation in neural populations </div>
    <div class="card-subtitle"> <!----Title---> Chi-Ning Chou, Royoung Kim, Luke A Arend, Yao-Yuan Yang, Brett D Mensh, Won Mok Shim, Matthew G Perich, SueYeon Chung </div> 
    <div class="card-body"> <!----Description---> We introduce GLUE (Geometry Linked to Untangling Efficiency) a data-driven analysis framework with manifold capacity theory, that links changes in the geometrical properties of neural activity patterns to representational untangling at the computational level. We applied GLUE to over seven neuroscience datasets—spanning multiple organisms, tasks, and recording techniques—and found that task-relevant representations untangle in many domains, including along the cortical hierarchy, through learning, and over the course of intrinsic neural dynamics. [<a id="external-link" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11996410/">pdf</a>] [<a id="external-link" href="assets/bib/chou2025geometry.html">bib</a>] <i> bioRxiv, 2025 </i> </div>
</div>


<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/pub_imgs/kirsanov2025geometry.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> The Geometry of Prompting: Unveiling Distinct Mechanisms of Task Adaptation in Language Models </div> 
    <div class="card-subtitle"> <!----Title---> Artem Kirsanov, Chi-Ning Chou, Kyunghyun Cho, SueYeon Chung</div> 
    <div class="card-body"> <!----Description---> We investigate how different prompting methods affect the geometry of representations in these models. Employing a framework grounded in statistical physics, we reveal that various prompting techniques, while achieving similar performance, operate through distinct representational mechanisms for task adaptation. Our analysis highlights the critical role of input distribution samples and label semantics in few-shot in-context learning. [<a id="external-link" href="https://arxiv.org/pdf/2502.08009">pdf</a>][<a id="external-link" href="assets/bib/kirsanov2025geometry.html">bib</a>] <i> NAACL, 2025 </i>  </div>
</div>


<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/wakhloo2024.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Neural Population Geometry and Optimal Coding of Tasks with Shared Latent Structure </div> 
    <div class="card-subtitle"> <!----Title---> Albert J. Wakhloo, Will Slatton, and SueYeon Chung </div> 
    <div class="card-body"> <!----Description---> Humans and animals can recognize latent structures in their environment and apply this information to efficiently navigate the world. Several recent works argue that the brain supports these abilities by forming neural representations that encode such latent structures in flexible, generalizable ways. However, it remains unclear what aspects of neural population activity are contributing to these computational capabilities. Here, we develop an analytical theory linking the mesoscopic statistics of a neural population’s activity to generalization performance on a multi-task learning problem.  [<a id="external-link" href="https://arxiv.org/pdf/2402.16770.pdf">pdf</a>] <i> arXiv, 2024 </i> </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/cohen-et-al.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Separability and geometry of object manifolds in deep neural networks </div> 
    <div class="card-subtitle"> <!----Title---> Uri Cohen*, Sueyeon Chung*, Daniel D. Lee, Haim Sompolinsky (*:co-first)</div> 
    <div class="card-body"> <!----Description---> We demonstrate that changes in the geometry of the associated object manifolds underlie this improved capacity, and shed light on the functional roles different levels in the hierarchy play to achieve it, through orchestrated reduction of manifolds’ radius, dimensionality and inter-manifold correlations. [<a id="external-link" href="https://www.nature.com/articles/s41467-020-14578-5.pdf">pdf</a>] [<a id="external-link" href="https://github.com/sompolinsky-lab/dnn-object-manifolds">code</a>] [<a id="external-link" href="assets/bib/cohen2020.html">bib</a>] <i> Nature Communications, 2020 </i>  </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/stephensen2020.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Untangling in Invariant Speech Recognition </div> 
    <div class="card-subtitle"> <!----Title--->Cory Stephenson, Jenelle Feather, Suchismita Padhy, Oguz Elibol, Hanlin Tang, Josh McDermott, SueYeon Chung </div> 
    <div class="card-body"> <!----Description---> Deep neural networks have achieved impressive performance in audio processing applications, both as sub-components of larger systems and as complete end-to-end systems by themselves. Despite their empirical successes, comparatively little is understood about how these audio models accomplish these tasks.In this work, we employ a recently developed statistical mechanical theory that connects geometric properties of network representations and the separability of classes to probe how information is untangled within neural networks trained to recognize speech. [<a id="external-link" href="https://proceedings.neurips.cc/paper/2019/file/e2db7186375992e729165726762cb4c1-Paper.pdf">pdf</a>] [<a id="external-link" href="https://github.com/schung039/neural_manifolds_replicaMFT">code</a>] [<a id="external-link" href="assets/bib/stephensen2020.html">bib</a>] <i> NeurIPS, 2019 </i> </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/dapello.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Neural Population Geometry Reveals the Role of Stochasticity in Robust Perception </div> 
    <div class="card-subtitle"> <!----Title---> Joel Dapello*, Jenelle Feather*, Hang Le*, Tiago Marques, David D. Cox, Josh H. McDermott, James J. DiCarlo, SueYeon Chung (*:co-first)</div> 
    <div class="card-body"> <!----Description---> Using recently developed geometrical techniques from computational neuroscience, we investigate how adversarial perturbations influence the internal representations of standard, adversarially trained, and biologically-inspired stochastic networks. We find distinct geometric signatures for each type of network, revealing different mechanisms for achieving robust representations. [<a id="external-link" href="https://proceedings.neurips.cc/paper/2021/file/8383f931b0cefcc631f070480ef340e1-Paper.pdf">pdf</a>] [<a id="external-link" href="https://github.com/chung-neuroai-lab/adversarial-manifolds">code</a>] [<a id="external-link" href="assets/bib/dapello.html">bib</a>] <i> NeurIPS, 2021</i> </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/yao-et-al.png" height="300px" width="200px"/>
    <div class="card-title">Transformation of acoustic information to sensory decision variables in the parietal cortex. </div> 
    <div class="card-subtitle"> Justin D. Yao*, Klavdia O. Zemlianova*, David L. Hockera, Cristina Savina, Christine M. Constantinople, SueYeon Chung,  and Dan H. Sanes. (*:co-first) </div> 
    <div class="card-body"> The process by which sensory evidence contributes to perceptual choices requires an understanding of its transformation into decision variables. Here, we address this issue by evaluating the neural representation of acoustic information in the auditory cortex- recipient parietal cortex, while gerbils either performed a two-alternative forced-choice auditory discrimination task or while they passively listened to identical acoustic stimuli. Our findings demonstrate how parietal cortex neurons integrate and transform encoded auditory information to guide sound-driven perceptual decisions[<a id="external-link" href="https://www.pnas.org/doi/epdf/10.1073/pnas.2212120120">pdf</a>] [<a id="external-link" href="assets/bib/yao2022.html">bib</a>] <i> PNAS, 2023 </i> </div>
</div>

</div>

<br>
<hr>
<h3> Neuro-inspired AI and brain-AI alignment </h3>
<div class="cards">

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/pub_imgs/yerxa2024contrastive.png" height="300px" width="200px"/>
    <div class="card-title"> <!----Title---> Contrastive-Equivariant Self-Supervised Learning Improves Alignment with Primate Visual Area IT </div>
    <div class="card-subtitle"> <!----Title---> Thomas Yerxa, Jenelle Feather, Eero Simoncelli, SueYeon Chung </div> 
    <div class="card-body"> <!----Description--->  We introduce a novel framework for converting standard invariant SSL losses into “contrastive-equivariant” versions that encourage preservation of input transformations without supervised access to the transformation parameters. We demonstrate that our proposed method systematically increases the ability of models to predict responses in macaque inferior temporal cortex. [<a id="external-link" href="https://openreview.net/pdf?id=AiMs8GPP5q">pdf</a>][<a id="external-link" href="assets/bib/yerxa2024contrastive.html">bib</a>] <i> NeurIPS, 2024 </i> </div> </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/canatar2023.png" height="300px" width="200px"/>
    <div class="card-title"> <!----Title---> A Spectral Theory of Neural Prediction and Alignment </div>
    <div class="card-subtitle"> <!----Title---> Abdulkadir Canatar*, Jenelle Feather*, Albert Wakhloo, SueYeon Chung </div> 
    <div class="card-body"> <!----Description--->  Many different state-of-the-art deep neural networks yield similar neural predictions, but it remains unclear how to differentiate among models that perform equally well at predicting neural responses. To gain insight into this, we use a recent theoretical framework that relates the generalization error from regression to the spectral bias of the model activations and the alignment of the neural responses onto the learnable subspace of the model. [<a id="external-link" href="https://openreview.net/pdf?id=5B1ZK60jWn">pdf</a>] [<a id="external-link" href="assets/bib/canatar2023.html">bib</a>] [<a id="external-link" href="https://github.com/chung-neuroai-lab/SNAP">code</a>] <i> Spotlight paper, NeurIPS, 2023 </i> </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/yerxa2023.png" height="300px" width="200px"/>
    <div class="card-title"> <!----Title---> Learning Efficient Coding of Natural Images with Maximum Manifold Capacity Representations </div>
    <div class="card-subtitle"> <!----Title---> Thomas Yerxa, Yilun Kuang, Eero Simoncelli, SueYeon Chung </div> 
    <div class="card-body"> <!----Description--->  [<a id="external-link" href="https://arxiv.org/pdf/2303.03307.pdf">pdf</a>][<a id="external-link" href="assets/bib/yerxa2023.html">bib</a>] <i> NeurIPS, 2023 </i> </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/clark-et-al.png" height="300px" width="200px"/>
    <div class="card-title"> Credit Assignment Through Broadcasting a Global Error Vector </div> 
    <div class="card-subtitle"> David G. Clark, L.F. Abbott, SueYeon Chung</div> 
    <div class="card-body"> Here, we explore the extent to which a globally broadcast learning signal, coupled with local weight updates, enables training of DNNs. We present both a learning rule, called global error-vector broadcasting (GEVB), and a class of DNNs, called vectorized nonnegative networks (VNNs), inwhich this learning rule operates.  [<a id="external-link" href="https://arxiv.org/pdf/2106.04089.pdf">pdf</a>] [<a id="external-link" href = "https://github.com/davidclark1/VectorizedNets">code</a>] [<a id="external-link" href="assets/bib/clark2021.html">bib</a>] <i> NeurIPS, 2021 </i> </div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/dapello.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Neural Population Geometry Reveals the Role of Stochasticity in Robust Perception </div> 
    <div class="card-subtitle"> <!----Title---> Joel Dapello*, Jenelle Feather*, Hang Le*, Tiago Marques, David D. Cox, Josh H. McDermott, James J. DiCarlo, SueYeon Chung (*:co-first) </div> 
    <div class="card-body"> <!----Description---> Using recently developed geometrical techniques from computational neuroscience, we investigate how adversarial perturbations influence the internal representations of standard, adversarially trained, and biologically-inspired stochastic networks. We find distinct geometric signatures for each type of network, revealing different mechanisms for achieving robust representations. [<a id="external-link" href="https://proceedings.neurips.cc/paper/2021/file/8383f931b0cefcc631f070480ef340e1-Paper.pdf">pdf</a>] [<a id="external-link" href="https://github.com/chung-neuroai-lab/adversarial-manifolds">code</a>] [<a id="external-link" href="assets/bib/dapello.html">bib</a>] <i> NeurIPS, 2021</i> </div>
</div>

</div>

</div>
