---
layout: default
is_grid: true
---

# Research Highlights

<br>
<h3> Theory of Neural Manifolds</h3>
<div class="cards">

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/wakhloo.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Linear Classification of Neural Manifolds with Correlated Variability </div>
    <div class="card-subtitle"> <!----Title---> <i>Albert J. Wakhloo, Tamara J. Sussman, and SueYeon Chung </i> </div> 
    <div class="card-body"> <!----Description--->  In this letter, we calculate how correlations between object representations affect the capacity, a measure of linear separability. We show that for spherical object manifolds, introducing correlations between centroids effectively pushes the spheres closer together, while introducing correlations between the spheres’ axes effectively shrinks their radii, revealing a duality between neural correlations and geometry [<a id="external-link" href="https://arxiv.org/pdf/2211.14961.pdf">pdf</a>][<a id="external-link" href="assets/bib/wakhloo.html">bib</a>]</div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/chung-and-abbott.png"/>
    <div class="card-title"> Neural population geometry: An approach for understanding biological and artificial neural networks</div> 
    <div class="card-subtitle"> SueYeon Chung, Larry Abbott </div> 
    <div class="card-body"> We highlight recent studies of neural population geometry: untangling in perception, classification theory of manifolds, abstraction in cognitive systems, topology underlying cognitive maps, dynamic untangling in motor systems, and a dynamic approach to cognition.   [<a id="external-link" href="https://reader.elsevier.com/reader/sd/pii/S0959438821001227?token=A35A4C64517A0C79DEC5D1818739BAABEB465C461F9E49F7DED819CB2B8B6A37596F353C4C04FA8C561E9CD86D2C1B2D&originRegion=us-east-1&originCreation=20230118192945">pdf</a>] [<a id="external-link" href="assets/bib/chung-and-abbott.html">bib</a>]</div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/chung2018.png" height="300px" width="200px"/>
    <div class="card-title"> <!----Title---> Classification and Geometry of General Perceptual Manifolds </div> 
    <div class="card-subtitle"> <!----Title---> <i>Sueyeon Chung, Daniel D. Lee, Haim Sompolinsky </i> </div> 
    <div class="card-body"> <!----Description---> s. We develop a statistical mechanical theory for the linear classification of manifolds with arbitrary geometry, revealing a remarkable relation to the mathematics of conic decomposition. We show how special anchor points on the manifolds can be used to define novel geometrical measures of radius and dimension, which can explain the classification capacity for manifolds of various geometries. [<a id="external-link" href="https://journals.aps.org/prx/pdf/10.1103/PhysRevX.8.031003">pdf</a>] [<a id="external-link" href="assets/bib/chung2018.html">bib</a>]</div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/chung2016.png" height="300px" width="200px"/>
    <div class="card-title"> <!----Title---> Linear readout of object manifolds </div> 
    <div class="card-subtitle"> <!----Title---> <i>Sueyeon Chung, Daniel D. Lee, Haim Sompolinsky </i> </div> 
    <div class="card-body"> <!----Description---> We present a theory that characterizes the ability of a linear readout network, the perceptron, to classify objects from variable neural responses. We show how the readout perceptron capacity depends on the dimensionality, size, and shape of the object manifolds in its input neural representation. [<a id="external-link" href="https://drive.google.com/file/d/1rtsSztFNUG5NcDcotVp5cJGfqIO59gqY/view">pdf</a>] [<a id="external-link" href="assets/bib/chung2016.html">bib</a>]</div>
</div>
</div>

<br>
<hr>
<h3> Manifold analysis in brain-inspired ANN models and neural data</h3>
<div class="cards">

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/stephensen2020.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Untangling in Invariant Speech Recognition </div> 
    <div class="card-subtitle"> <!----Title---> <i>Cory Stephenson, Jenelle Feather, Suchismita Padhy, Oguz Elibol, Hanlin Tang, Josh McDermott, SueYeon Chung </i> </div> 
    <div class="card-body"> <!----Description---> Deep neural networks have achieved impressive performance in audio processing applications, both as sub-components of larger systems and as complete end-to-end systems by themselves. Despite their empirical successes, comparatively little is understood about how these audio models accomplish these tasks.In this work, we employ a recently developed statistical mechanical theory that connects geometric properties of network representations and the separability of classes to probe how information is untangled within neural networks trained to recognize speech. [<a id="external-link" href="https://proceedings.neurips.cc/paper/2019/file/e2db7186375992e729165726762cb4c1-Paper.pdf">pdf</a>] [<a id="external-link" href="https://github.com/schung039/neural_manifolds_replicaMFT">code</a>] [<a id="external-link" href="assets/bib/stephensen2020.html">bib</a>]</div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/cohen-et-al.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Separability and geometry of object manifolds in deep neural networks </div> 
    <div class="card-subtitle"> <!----Title---> <i>Uri Cohen, Sueyeon Chung, Daniel D. Lee, Haim Sompolinsky </i> </div> 
    <div class="card-body"> <!----Description---> We demonstrate that changes in the geometry of the associated object manifolds underlie this improved capacity, and shed light on the functional roles different levels in the hierarchy play to achieve it, through orchestrated reduction of manifolds’ radius, dimensionality and inter-manifold correlations. [<a id="external-link" href="https://www.nature.com/articles/s41467-020-14578-5.pdf">pdf</a>] [<a id="external-link" href="https://github.com/sompolinsky-lab/dnn-object-manifolds">code</a>] [<a id="external-link" href="assets/bib/cohen2020.html">bib</a>]</div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/cohen-et-al.png" height="300px" width="200px"/>
   <div class="card-title"> <!----Title---> Neural Population Geometry Reveals the Role of Stochasticity in Robust Perception </div> 
    <div class="card-subtitle"> <!----Title---> <i>Joel Dapello, Jenelle Feather, Hang Le, Tiago Marques, David D. Cox, Josh H. McDermott, James J. DiCarlo, SueYeon Chung </i> </div> 
    <div class="card-body"> <!----Description---> using recently developed geometrical techniques from computational neuroscience, we investigate how adversarial perturbations influence the internal representations of standard, adversarially trained, and biologically-inspired stochastic networks. We find distinct geometric signatures for each type of network, revealing different mechanisms for achieving robust representations. [<a id="external-link" href="https://proceedings.neurips.cc/paper/2021/file/8383f931b0cefcc631f070480ef340e1-Paper.pdf">pdf</a>] [<a id="external-link" href="https://github.com/chung-neuroai-lab/adversarial-manifolds">code</a>] [<a id="external-link" href="assets/bib/dapello.html">bib</a>]</div>
</div>

<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/yao-et-al.png"/>
    <div class="card-title">Transformation of acoustic information to sensory decision variables in the parietal cortex. </div> 
    <div class="card-subtitle"> Justin D. Yao, Klavdia O. Zemlianovaa, David L. Hockera, Cristina Savina, Christine M. Constantinople, SueYeon Chung,  and Dan H. Sanes. </div> 
    <div class="card-body"> The process by which sensory evidence contributes to perceptual choices requires an understanding of its transformation into decision variables. Here, we address this issue by evaluating the neural representation of acoustic information in the auditory cortex- recipient parietal cortex, while gerbils either performed a two-alternative forced-choice auditory discrimination task or while they passively listened to identical acoustic stimuli. Our findings demonstrate how parietal cortex neurons integrate and transform encoded auditory information to guide sound-driven perceptual decisions[<a id="external-link" href="https://www.pnas.org/doi/epdf/10.1073/pnas.2212120120">pdf</a>] [<a id="external-link" href="assets/bib/yao2022.html">bib</a>]</div>
</div>

</div>

<br>
<hr>
<h3> Bioplausible Learning</h3>
<div class="cards">
<div class="card">
    <img class="card-img" src="{{site.baseurl | prepend:site.url}}assets/img/clark-et-al.png"/>
    <div class="card-title"> Credit Assignment Through Broadcasting a Global Error Vector </div> 
    <div class="card-subtitle"> David G. Clark, L.F. Abbott, SueYeon Chung</div> 
    <div class="card-body"> Here, we explore the extent to which a globally broadcast learning signal, coupled with local weight updates, enables training of DNNs. We present both a learning rule, called global error-vector broadcasting (GEVB), and a class of DNNs, called vectorized nonnegative networks (VNNs), inwhich this learning rule operates.  [<a id="external-link" href="https://arxiv.org/pdf/2106.04089.pdf">pdf</a>] [<a id="external-link" href = "https://github.com/davidclark1/VectorizedNets">code</a>] [<a id="external-link" href="assets/bib/clark2021.html">bib</a>]</div>
</div>

</div>